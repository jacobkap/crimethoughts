---
title: Correlation is causation
author: Jacob Kaplan
date: '2022-06-07'
slug: correlation-is-causation
categories:
  - Academia
tags:
  - academia
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>One of the most common tropes when talking about research is that “correlation isn’t causation.” This is generally used in opposition of the research at hand. Don’t like the findings? You can just say that correlation isn’t causation and dismiss it.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Academics also like to use this phrase defensively about their own research. If they do a correlational study and find something they don’t like (say, that X policy they support is related to more crime) they can say that it’s only a correlational study so policy changes should wait until further research. This is also, I believe, a defense mechanism among academics against having to take responsibility for their study’s findings. If they write a correlational paper and someone makes a policy from its findings, then that’s the policy maker just going beyond the study’s findings. The author bears no responsibility for that outcome. This is a very foolish point of view.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>Research does not exist in a silo. For it to be useful we need people outside of academia to read it and use it. That means that people are going to take correlational research and treat it as if it was causal. That’s partly out of misunderstanding of the stats - and academic papers do not make it easy to understand the data/methods - and partly because, for political topics especially, people will latch onto convenient research no matter if it’s causal or not. But the outcome is the same. Many people will treat correlational research as causal. To pretend otherwise, to pretend that your research will stay among the academics and never move into the real world where people cannot spends hours fully reading your paper (and where they probably don’t have the skills to do so anyways) is beyond foolish. It is dangerous and will lead to bad policy.</p>
<p>Let’s look at one extremely prominent example: the paper “Presence of Armed School Officials and Fatal and Nonfatal Gunshot Injuries During Mass School Shootings, United States, 1980-2019” published in JAMA last year by Drs. Peterson, Densley, and Erickson, who are criminologists (available to read <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2776515">here</a>). This paper, following the standard of public health papers, is four pages long and looks at a bunch of variables in school shooting cases (N=133) and sees what’s related to the number of people killed or injured. The finding that’s getting a ton of attention in light of the shooting in Uvalde, TX, is that schools with an armed police officer have a statistically significant increase in the number of people killed though no effect on number injured. There’s no experimental or quasi-experimental changes here so you cannot determine causality, it is purely a correlational study. There are data/methods issues in this study such as only looking at schools with shootings (so no way to look at deterrent effect and assuming officers are assigned randomly), using data which the authors refuse to release publicly, imputing (somehow) missing data for key variables, but the key issue is that it’s correlational. It’s a cross-sectional study meaning you can’t say that any variable causes changes in the outcome. To the author’s credit they never make such a claim. Their discussion section is rightly free from any causal language.</p>
<p>That’s not how the paper is being used. It’s use in the media and discussions of responses to school shootings is treated as causal - that having police at schools makes school shootings deadlier. The first author of that paper, Dr. Peterson, was a guest of Jake Tapper’s show on CNN and that clip (and the paper’s findings) was also included in John Oliver’s show <a href="https://www.youtube.com/watch?v=KgwqQGvYt0g&amp;feature=emb_title">Last Week Tonight</a>. This means that the JAMA paper was talked about in front of millions of people, putting it at the top .01% (if not higher) of papers in terms of attention and policy relevance. This is what Oliver said in relation to the study: “If school cops <strong>can make</strong> shootings worse, why then are we still pitching them as a solution? [emphasis added]” This is clearly causal language, that the school police cause worse shootings and therefore it is bad policy to have this. This may in fact be true - but this paper cannot make that claim.</p>
<p>In this post I use the example of the JAMA paper but it’s certainly not the only one. I use it merely as an example of a recent and extremely popular paper that’s influencing policy - or at least attention on the topic - today. Many if not most criminology papers are correlational and have similar issues. And these papers tend to go much further than the JAMA paper in their discussion section. Whereas the JAMA remained purely discussing the findings, many papers talk about the relevant policy interventions that could lead to changes in the outcome by affecting the correlated variable… which is treating that correlation as if it was causal. If the paper uses causal language, why should a non-researcher think otherwise?</p>
<p>Here’s an example of this from a random recent paper that is representative of these issues but by no means is particularly bad about it. A <a href="https://www.sciencedirect.com/science/article/pii/S0091743517304759#s0040">cross-section study</a> finds a positive relationship between energy drink consumption among teenagers and using drugs. How does the conclusion section start? By treating the results as if they were causal and arguing for policy change: “The findings from this study suggest that policies that permit children and young adolescents to consume energy drinks may need to be reconsidered…Our findings also buttress the notion that adolescent energy drink consumption represents a significant public health concern.” Even the very first sentence in the paper, in the “Highlights” section says the relationship is causal: “This study demonstrated that energy drinks <strong>may begin</strong> the drug use cycle. [emphasis added]” This is ubiquitous in criminology research<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Correlational results section, causal discussion/conclusion section.</p>
<p>So what’s the solution to these issues - non-academics treating correlation as causation and academics doing the same? The second part is an easier fix. Authors should stop using causal language - including recommending policy changes - in correlational papers. Editors should enforce this. Some of this also also caused by journals themselves as even in correlational papers reviewers and editors will want to see policy recommendations. This forces authors to use causal language pushing for policy changes even in these correlational papers, and even if they know it is inappropriate. Here again editors have the power and responsibility to stop this.</p>
<p>We also need far more actually causal papers and fewer correlational papers. Criminology has a huge quantity over quality problem. The more papers you push out, largely regardless of quality, the more successful you will be. Causal papers are a lot harder than correlational papers. You usually can’t just download some data and plug in a regression for causal research. Given the increased difficulty - and reduced rewards of fewer better papers over many worse papers - it makes sense people will gravitate towards the easy work.</p>
<p>I doubt this will happen because editors need papers to fill journals and researchers need papers to fill CVs. But having fewer papers that are higher quality and actually get at the causal question which is crucial for policy would not only help the issue of people misidentifying papers as causal when they aren’t (since in this world more papers would actually be causal) it would make the overall body of research better. And would make our work as researchers more useful since we can actually say what the effect of X or Y policy is on crime - you know, the entire point of criminology. Non-academics are going to misuse (sometimes accidentally, sometimes intentionally) research. Researchers should push back at this bad usage by explaining publicly what we can and cannot learn from it. But we’ll still have these issues. There’s no solution, only ways to mitigate the problem.</p>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>People also like to do this even when the research is actually causal, such as through an experiment or natural experiment, though most research really is only correlational.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>And academics love to be foolish when it benefits them.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>And likely many other fields though I am most familiar with criminology.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
